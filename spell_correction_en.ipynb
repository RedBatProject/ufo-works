{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wvZmnB9sjsKO"
      ],
      "mount_file_id": "1QG2dPqDUB05MSLljSzCgMMsEsbxgt-Jk",
      "authorship_tag": "ABX9TyOY2ZNMfM72fpqI7Y086Nab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RedBatProject/ufo-works/blob/main/spell_correction_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "bnGF72SxjXYb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "3DYpDguJjPYH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "_NNNgShPJ-CU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# work with data"
      ],
      "metadata": {
        "id": "MNXQKeq7jQKO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gt4UZHtCP7bD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mPf6fQXzP5IJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"oknerazan/english_sentences\",streaming=True)"
      ],
      "metadata": {
        "id": "_erDObVkP3Qj"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NCbWfTboQh8t"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = []\n",
        "wor = []\n",
        "for ind,i in enumerate(dataset['train']):\n",
        "    sent.append(re.sub(\"[^A-za-z0-9 ]\",'',i['sentence'].lower()))\n",
        "    wor.append(i['word'])\n",
        "    if ind == 1000:\n",
        "        break"
      ],
      "metadata": {
        "id": "qK7DObSvQJZt"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2GrhIpDtBkP0",
        "outputId": "127c7fce-e4e1-4925-b997-c5ca43e1c5bb"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a simple black spider is a fast face painting design that can make a big impact come halloween'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join([i for i in sent])"
      ],
      "metadata": {
        "id": "BOdnaSV4RVG4"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a7Li8_gTSIez"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = Counter(text)"
      ],
      "metadata": {
        "id": "p8xzDRiFSH8q"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = list(alpha.keys())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zH3KroYYSR9O"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7XWNIoISajp",
        "outputId": "5ddec03a-f877-4b26-f986-bff4dd20ee71"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " ' ',\n",
              " 's',\n",
              " 'i',\n",
              " 'm',\n",
              " 'p',\n",
              " 'l',\n",
              " 'e',\n",
              " 'b',\n",
              " 'c',\n",
              " 'k',\n",
              " 'd',\n",
              " 'r',\n",
              " 'f',\n",
              " 't',\n",
              " 'n',\n",
              " 'g',\n",
              " 'h',\n",
              " 'o',\n",
              " 'w',\n",
              " 'u',\n",
              " 'y',\n",
              " 'v',\n",
              " 'x',\n",
              " 'z',\n",
              " 'j',\n",
              " '1',\n",
              " '0',\n",
              " 'q',\n",
              " '2',\n",
              " '9',\n",
              " '8',\n",
              " '4',\n",
              " '5',\n",
              " '3',\n",
              " '6']"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alpha.remove(\"'\")\n",
        "# alpha.remove('\"')\n"
      ],
      "metadata": {
        "id": "Qywuv3vfSxmW"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(alpha)\n",
        "# alpha"
      ],
      "metadata": {
        "id": "62JrWdZtSmKQ"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.randint(1,(10,10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EULTtP3LTFX5",
        "outputId": "262790d5-854a-43e0-ebd9-6c8b30c8b4a7"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.randint(0,10,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5lcHRww-WQE",
        "outputId": "eb0a579f-a7e2-46f0-bc72-4d8ac389d2f7"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 5, 4, 5, 4, 8, 2, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L1oic0q2EBxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corruption(word):\n",
        "    word2 = word\n",
        "    step1 = len(word)\n",
        "    np.random.shuffle(alpha)\n",
        "    x = np.random.randint(0,step1)\n",
        "    x = 2\n",
        "    for i in range(x):\n",
        "        y = np.random.randint(0,step1)\n",
        "        # word2[y] = alpha[y]\n",
        "        k = [*word2]\n",
        "        k[y] = alpha[y]\n",
        "        word2 = ''.join([t for t in k])\n",
        "    return word2"
      ],
      "metadata": {
        "id": "kEn50nRdSYFG"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sent"
      ],
      "metadata": {
        "id": "z3BzpdXvBemc"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwmKFQOEBznn",
        "outputId": "55744d44-f6e1-4a9c-8415-ae9434fbf4a9"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3, 12,  6, 13,  3,  3])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(set(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxX8abGRB2FN",
        "outputId": "6b1cf327-e9ff-4efe-bd61-a6a693b79a26"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 12, 13, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CxRGJ3fEEWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"oknerazan/english_sentences\",streaming=True)\n",
        "\n",
        "sent = []\n",
        "wor = []\n",
        "for ind,i in enumerate(dataset['train']):\n",
        "    sent.append(re.sub(\"[^A-za-z0-9 ]\",'',i['sentence'].lower()))\n",
        "    wor.append(i['word'])\n",
        "    if ind == 1000:\n",
        "        break\n",
        "\n",
        "text = ' '.join([i for i in sent])\n",
        "alpha = Counter(text)\n",
        "alpha = list(alpha.keys())\n",
        "def corruption(word):\n",
        "    word2 = word\n",
        "    step1 = len(word)\n",
        "    np.random.shuffle(alpha)\n",
        "    x = np.random.randint(0,step1)\n",
        "    x = 1\n",
        "    for i in range(x):\n",
        "        y = np.random.randint(0,step1)\n",
        "        # word2[y] = alpha[y]\n",
        "        k = [*word2]\n",
        "        k[y] = alpha[y]\n",
        "        word2 = ''.join([t for t in k])\n",
        "    return word2\n",
        "dataset = []\n",
        "ww = []\n",
        "corword = []\n",
        "for i in sent:\n",
        "    # print(i,j)\n",
        "    j = i.split()\n",
        "    c = int(len(j)//5)\n",
        "    if c ==0:\n",
        "        c =1\n",
        "    c = 1\n",
        "    x = np.random.randint(0,len(j),c)\n",
        "    for ki in list(set(x)):\n",
        "        # print(x)\n",
        "        # x = int(x)\n",
        "        k = corruption(j[ki])\n",
        "        corword.append(j[ki])\n",
        "\n",
        "        i = re.sub(j[ki],k,i)\n",
        "        ww.append(k)\n",
        "    # print(i)\n",
        "    dataset.append(i)\n",
        "    # break"
      ],
      "metadata": {
        "id": "VsPdACfmUsqx"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.DataFrame()\n",
        "d['org_text'] = sent\n",
        "# d['org_word'] = corword\n",
        "d['wrong_text'] = dataset\n",
        "# d['wrong_word'] = ww\n",
        "d.to_csv('/content/drive/MyDrive/roshan_english_data/data_1000_en_alph_v3.csv',index=False)"
      ],
      "metadata": {
        "id": "ySWG5Op-ZN7L"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# work with model"
      ],
      "metadata": {
        "id": "6wCP9uf9jFxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.read_csv('/content/drive/MyDrive/roshan_english_data/data_1000_en_alph_v3.csv')"
      ],
      "metadata": {
        "id": "SNU6BGkqi4kP"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = d['org_text']"
      ],
      "metadata": {
        "id": "IVW1NUQfjh5j"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kJXOhU4WZ0L0",
        "outputId": "250483e8-018f-42f0-ec89-0aa33a025029"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              org_text  \\\n",
              "0    a simple black spider is a fast face painting ...   \n",
              "1    such fossils are usually fragmentary and conta...   \n",
              "2    a recently discovered fossil group the pterido...   \n",
              "3    the moral balance model proposes that most hum...   \n",
              "4                          that fossil down the street   \n",
              "..                                                 ...   \n",
              "305  fossil is a more affordable option than some o...   \n",
              "306  also you can find numerous fossils and petrifi...   \n",
              "307  look ive never met a fossil that old in my ent...   \n",
              "308           well not a bad presentation for a fossil   \n",
              "309  the stormberg group contains south africas ear...   \n",
              "\n",
              "                                            wrong_text  \n",
              "0    a simple black spider is a fast face painting ...  \n",
              "1    such fossils arv usually fragmentary and conta...  \n",
              "2    a pecently discovered fossil group the pterido...  \n",
              "3    4he moral balance model proposes that most hum...  \n",
              "4                          that fossil down the stre4t  \n",
              "..                                                 ...  \n",
              "305  fossil is a more affordable option than some o...  \n",
              "306  also you c3n find numerous fossils and petrifi...  \n",
              "307  look iv6 never met a fossil that old in my ent...  \n",
              "308           well not a bad presentation ffr a fossil  \n",
              "309  the stormberg group contains south africas ear...  \n",
              "\n",
              "[310 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-512dc335-b52c-40ff-9997-1675cb401eb7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>org_text</th>\n",
              "      <th>wrong_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a simple black spider is a fast face painting ...</td>\n",
              "      <td>a simple black spider is a fast face painting ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>such fossils are usually fragmentary and conta...</td>\n",
              "      <td>such fossils arv usually fragmentary and conta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a recently discovered fossil group the pterido...</td>\n",
              "      <td>a pecently discovered fossil group the pterido...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the moral balance model proposes that most hum...</td>\n",
              "      <td>4he moral balance model proposes that most hum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>that fossil down the street</td>\n",
              "      <td>that fossil down the stre4t</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>fossil is a more affordable option than some o...</td>\n",
              "      <td>fossil is a more affordable option than some o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>also you can find numerous fossils and petrifi...</td>\n",
              "      <td>also you c3n find numerous fossils and petrifi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>look ive never met a fossil that old in my ent...</td>\n",
              "      <td>look iv6 never met a fossil that old in my ent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>well not a bad presentation for a fossil</td>\n",
              "      <td>well not a bad presentation ffr a fossil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>the stormberg group contains south africas ear...</td>\n",
              "      <td>the stormberg group contains south africas ear...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>310 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-512dc335-b52c-40ff-9997-1675cb401eb7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-512dc335-b52c-40ff-9997-1675cb401eb7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-512dc335-b52c-40ff-9997-1675cb401eb7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a998c8c4-89c3-4d72-8b9e-91693ea39e6b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a998c8c4-89c3-4d72-8b9e-91693ea39e6b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a998c8c4-89c3-4d72-8b9e-91693ea39e6b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "d",
              "summary": "{\n  \"name\": \"d\",\n  \"rows\": 310,\n  \"fields\": [\n    {\n      \"column\": \"org_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 310,\n        \"samples\": [\n          \"wedding programs are an important part of the day and the blank alternative provides a flexible and interesting choice for couples to consider\",\n          \"the coursework offered by auburn university is not as comprehensive as other programs but is certainly flexible if you can find the time and money\",\n          \"you all really think im a fossil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wrong_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 310,\n        \"samples\": [\n          \"wedding programs are an important part 4f the day and the blank alternative provides a flexible and interesting choice for couples to consider\",\n          \"the coursework offered by auburn university is not as comprehensive as other 8rograms but is certainly flexible if you can find the time and money\",\n          \"you all really think im a fosmil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install jiwer\n",
        "clear_output()\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "vTac6bOyVIsV"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the WER and CER metrics from the evaluate package\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "cer_metric = evaluate.load(\"cer\")"
      ],
      "metadata": {
        "id": "a4GGn8SqYuGQ"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = d['wrong_text']\n",
        "references = d['org_text']"
      ],
      "metadata": {
        "id": "Acocm1riYyda"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset"
      ],
      "metadata": {
        "id": "GUyngjqPY59q"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute WER\n",
        "wer_result = wer_metric.compute(predictions=predictions, references=references)\n",
        "print(\"WER:\", wer_result)\n",
        "\n",
        "# Compute CER\n",
        "cer_result = cer_metric.compute(predictions=predictions, references=references)\n",
        "print(\"CER:\", cer_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALVa2Rb2YwWX",
        "outputId": "cb09db1d-fc99-42ef-9224-6dd39562f8a8"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 0.0941972920696325\n",
            "CER: 0.016502314348963574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "clear_output()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hwEdTkddY-Dj"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## feed the model with dataset"
      ],
      "metadata": {
        "id": "1i34KPmgj1z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sen = sent[0]\n",
        "s = []\n",
        "sentence = 'how aro you doing today'\n",
        "u = sentence.split()\n",
        "for ind,i in enumerate(u):\n",
        "    l = ' '.join([u[c] if ind!=c else '[MASK]' for c in range(len(u))])\n",
        "    s.append(l)"
      ],
      "metadata": {
        "id": "S1ToMM_ScQ1y"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb-9mXYNdOZW",
        "outputId": "97e81a55-b29e-47b8-cec9-b1f80267d293"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[MASK] aro you doing today',\n",
              " 'how [MASK] you doing today',\n",
              " 'how aro [MASK] doing today',\n",
              " 'how aro you [MASK] today',\n",
              " 'how aro you doing [MASK]']"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "WtH1i_Gjdp9L"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "LYk33HgBdoEe"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "both = []\n",
        "for i,j in zip(predictions,references):\n",
        "    both.append(i)\n",
        "    both.append(j)"
      ],
      "metadata": {
        "id": "TDC19_as6G8U"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u = []\n",
        "sem = []\n",
        "ler = []"
      ],
      "metadata": {
        "id": "i8dSiR5ZE3_3"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.input_ids.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv-DSSmkIEsf",
        "outputId": "73e16a63-414e-4cb9-ac3e-5c67252b6189"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in both:\n",
        "    # print(sentence)\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "    # print(inputs['input_ids'])\n",
        "    masked_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "    # print(masked_index)\n",
        "    # inputs['input_ids'][0][4] = 103\n",
        "    # Get predictions for the masked token\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs.to(device))\n",
        "    h = torch.softmax(outputs.logits[0], dim=1).max(1)[0]\n",
        "    sem.append(sentence)\n",
        "    u.append(round(h[1:-1].mean().item(),4))\n",
        "    ler.append(inputs.input_ids.shape[1])\n",
        "    # print('Score for this sentence is: ',round(h[1:-1].mean().item(),4))\n",
        "    # try:\n",
        "    #     masked_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "    #     predicted_token_ids = torch.topk(outputs.logits[0, masked_index], k=5).indices\n",
        "    #     predicted_tokens = [''.join(tok for tok in tokenizer.decode(token_id).split(' ')) for token_id in predicted_token_ids[0]]\n",
        "    #     print('Best Predicted Word: ',predicted_tokens)\n",
        "    # except Exception as e:\n",
        "    #     # print('oops!',e)\n",
        "    #     pass\n",
        "    # # for i,j in zip(inputs['input_ids'][0].tolist(),h.tolist()):\n",
        "    #     # print(f'{tokenizer.decode(i):<15} |  {i:<10} | {j:.4f} |')\n",
        "    # print(50*'-')"
      ],
      "metadata": {
        "id": "Kv7Ajkg_546C"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = pd.DataFrame()\n",
        "s['sentence'] = sem\n",
        "s['score'] = u\n",
        "s['len'] = ler"
      ],
      "metadata": {
        "id": "0CJD8DZHIXmy"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "auRufcGGL5Ju",
        "outputId": "a617a497-da07-4269-c5c7-e7c5deeac0ab"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sentence   score  len\n",
              "0    a simule b6ack spider is a fast face painting ...  0.9239   24\n",
              "1    a simple black spider is a fast face painting ...  0.9447   20\n",
              "2    such qossils are usually qragmentary and conta...  0.8816   17\n",
              "3    such fossils are usually fragmentary and conta...  0.7715   13\n",
              "4    a recently discovered dossil group ths pterido...  0.9157   34\n",
              "..                                                 ...     ...  ...\n",
              "615  look ive never met a fossil that old in my ent...  0.8415   15\n",
              "616           well kot a bad presentation for a fossil  0.9248   11\n",
              "617           well not a bad presentation for a fossil  0.9616   10\n",
              "618  the stormberg grocp contains south africas ear...  0.7180   15\n",
              "619  the stormberg group contains south africas ear...  0.7987   13\n",
              "\n",
              "[620 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f474cdef-05ac-4edf-8098-0c8b730cc664\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>score</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a simule b6ack spider is a fast face painting ...</td>\n",
              "      <td>0.9239</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a simple black spider is a fast face painting ...</td>\n",
              "      <td>0.9447</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>such qossils are usually qragmentary and conta...</td>\n",
              "      <td>0.8816</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>such fossils are usually fragmentary and conta...</td>\n",
              "      <td>0.7715</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a recently discovered dossil group ths pterido...</td>\n",
              "      <td>0.9157</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>look ive never met a fossil that old in my ent...</td>\n",
              "      <td>0.8415</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>well kot a bad presentation for a fossil</td>\n",
              "      <td>0.9248</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>617</th>\n",
              "      <td>well not a bad presentation for a fossil</td>\n",
              "      <td>0.9616</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>the stormberg grocp contains south africas ear...</td>\n",
              "      <td>0.7180</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>619</th>\n",
              "      <td>the stormberg group contains south africas ear...</td>\n",
              "      <td>0.7987</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>620 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f474cdef-05ac-4edf-8098-0c8b730cc664')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f474cdef-05ac-4edf-8098-0c8b730cc664 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f474cdef-05ac-4edf-8098-0c8b730cc664');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fbe68367-1ea6-4094-b054-a4b1c0614cde\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fbe68367-1ea6-4094-b054-a4b1c0614cde')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fbe68367-1ea6-4094-b054-a4b1c0614cde button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "s",
              "summary": "{\n  \"name\": \"s\",\n  \"rows\": 620,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 620,\n        \"samples\": [\n          \"use crosses the line to abuse when it begins to affect everyday life cause social problems andor impact a teens physical well being\",\n          \"many marine fossils demonstrate the geological pasc of the aaea\",\n          \"while maiy experts are behind eaeh cruise to insure its flawless evecution passengers need to be flexible in order to enjoy their va6ations thoroughly\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.058114350601809445,\n        \"min\": 0.657,\n        \"max\": 0.9926,\n        \"num_unique_values\": 539,\n        \"samples\": [\n          0.9055,\n          0.8316,\n          0.8591\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 6,\n        \"max\": 72,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          23,\n          41,\n          54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## find best replacement"
      ],
      "metadata": {
        "id": "naUchIGlOoon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(forscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alnhpHwdQt-7",
        "outputId": "2a3f5ba2-9c7c-4e2c-f94d-a21be5078e6c"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hj = []\n",
        "# for i in predictions[0:1]:\n",
        "#     predictions[0:1]"
      ],
      "metadata": {
        "id": "34WdSlI4Wn5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Gbest = []\n",
        "for sentence in predictions:\n",
        "    Lbest = []\n",
        "    SLbest = []\n",
        "    for snd,sentenc in enumerate(sentence.split()):\n",
        "        kj2 = sentence.split()\n",
        "        kj2[snd] = '[MASK]'\n",
        "        sentencer = \" \".join([i for i in kj2])\n",
        "        inputs = tokenizer(sentencer, return_tensors='pt')\n",
        "        masked_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs.to(device))\n",
        "        h = torch.softmax(outputs.logits[0], dim=1).max(1)[0]\n",
        "        try:\n",
        "            masked_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "            predicted_token_ids = torch.topk(outputs.logits[0, masked_index], k=5).indices\n",
        "            predicted_tokens = [''.join(tok for tok in tokenizer.decode(token_id).split(' ')) for token_id in predicted_token_ids[0]]\n",
        "        except Exception as e:\n",
        "            pass\n",
        "        try:\n",
        "            kj = sentence.split()\n",
        "            if \"##\" in predicted_tokens[0]:\n",
        "\n",
        "                kj2[snd] = ''\n",
        "                kj2[snd-1] = kj2[snd-1] + predicted_tokens[0][2:]\n",
        "            else:\n",
        "                kj2[snd] = predicted_tokens[0]\n",
        "\n",
        "            sentencer = \" \".join([i for i in kj2])\n",
        "            sentencer = re.sub('  ',' ',sentencer)\n",
        "            inputs = tokenizer(sentencer, return_tensors='pt')\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs.to(device))\n",
        "            h = torch.softmax(outputs.logits[0], dim=1).max(1)[0]\n",
        "            sd2 = round(h[1:-1].mean().item(),4)\n",
        "            inputs = tokenizer(sentence, return_tensors='pt')\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs.to(device))\n",
        "            h = torch.softmax(outputs.logits[0], dim=1).max(1)[0]\n",
        "            sd1 = round(h[1:-1].mean().item(),4)\n",
        "            SLbest.append(sd2-sd1)\n",
        "            Lbest.append(sentencer)\n",
        "        except Exception as e:\n",
        "            print('oops!',e)\n",
        "    Gbest.append(Lbest[np.argmax(SLbest)])"
      ],
      "metadata": {
        "id": "kx9UYm2iOq_W"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Z44CM0WCiwfT",
        "outputId": "56116fd2-9def-4ed2-d688-d90a5f865ecb"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'such fossils arv usually fragmentary and contain no soft tissue'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Gbest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VakgNoALiG7r",
        "outputId": "6f03bfc1-49d1-4a6c-cd91-d175778a6963"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a simple black spider is a fast faceless design that can make a big iwpact come halloween',\n",
              " 'such an arv usually fragmentary and contain no soft tissue']"
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Gbest = []\n",
        "for sentence in predictions[3:4]:\n",
        "    Lbest = []\n",
        "    SLbest = []\n",
        "    for snd,sentenc in enumerate(sentence.split()):\n",
        "        kj2 = sentence.split()\n",
        "        kj2[snd] = '[MASK]'\n",
        "        sentencer = \" \".join([i for i in kj2])\n",
        "        # print(sentencer)\n",
        "        inputs = tokenizer(sentencer, return_tensors='pt')\n",
        "        masked_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs.to(device))\n",
        "        h = torch.softmax(outputs.logits[0], dim=1).max(1)[0]\n",
        "        try:\n",
        "            masked_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "            predicted_token_ids = torch.topk(outputs.logits[0, masked_index], k=5).indices\n",
        "            predicted_tokens = [''.join(tok for tok in tokenizer.decode(token_id).split(' ')) for token_id in predicted_token_ids[0]]\n",
        "            # print('Best Predicted Word: ',predicted_tokens)\n",
        "        except Exception as e:\n",
        "            # print('oops!',e)\n",
        "            pass\n",
        "        try:\n",
        "            kj = sentence.split()\n",
        "            if \"##\" in predicted_tokens[0]:\n",
        "\n",
        "                kj2[snd] = ''\n",
        "                kj2[snd-1] = kj2[snd-1] + predicted_tokens[0][2:]\n",
        "                # print(kj2)\n",
        "            else:\n",
        "                kj2[snd] = predicted_tokens[0]\n",
        "\n",
        "            sentencer = \" \".join([i for i in kj2])\n",
        "            # print(sentencer)\n",
        "            # forsentence.append(sentencer)\n",
        "            inputs = tokenizer(sentencer, return_tensors='pt')\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs.to(device))\n",
        "            h = torch.softmax(outputs.logits[0], dim=1).max(1)[0]\n",
        "            sd2 = round(h[1:-1].mean().item(),4)\n",
        "            # print('Score for this sentence is: ',round(h[1:-1].mean().item(),4))\n",
        "            inputs = tokenizer(sentence, return_tensors='pt')\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs.to(device))\n",
        "            h = torch.softmax(outputs.logits[0], dim=1).max(1)[0]\n",
        "            sd1 = round(h[1:-1].mean().item(),4)\n",
        "            # print('Score for this sentence is: ',round(h[1:-1].mean().item(),4))\n",
        "            # print(sd2-sd1)\n",
        "            # p.append(sd2-sd1)\n",
        "            # print(50*'-')\n",
        "            SLbest.append(sd2-sd1)\n",
        "            Lbest.append()\n",
        "        except Exception as e:\n",
        "            print('oops!',e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBe8ccGFX9gx",
        "outputId": "d05d3f98-a89c-44dc-a044-ec3f32e4816b"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forscores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFeorme2RIzK",
        "outputId": "ea4a2fd8-702f-4a68-8e1d-c528cdb93028"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a simple black spider is a fast face painting design that can make a big iwpact come [MASK]']"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-VMfRVMkTCLX"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u = 'a simple black spider is a fast face painting design that can make a big impavt on halloween'\n",
        "# Score for this sentence is:  0.9627\n",
        "Best_Predicted_Word = ['big', 'little', 'small', 'large', 'super']\n",
        "\n",
        "inputs = tokenizer(u, return_tensors='pt')\n",
        "# print(inputs['input_ids'])\n",
        "masked_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "# print(masked_index)\n",
        "# inputs['input_ids'][0][4] = 103\n",
        "# Get predictions for the masked token\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs.to(device))\n",
        "h = torch.softmax(outputs.logits[0], dim=1).max(1)[0]\n",
        "# sem.append(sentencer)\n",
        "# u.append(round(h[1:-1].mean().item(),4))\n",
        "# forscore.append(round(h[1:-1].mean().item(),4))\n",
        "# ler.append(inputs.input_ids.shape[1])\n",
        "print('Score for this sentence is: ',round(h[1:-1].mean().item(),4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D1ThnKbTHmj",
        "outputId": "fc479d84-d775-413d-aa20-b54d1b229b78"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for this sentence is:  0.9704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "\n",
        "def find_misspelled_words(sentence):\n",
        "    # Load pre-trained model tokenizer (vocabulary)\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Tokenize input\n",
        "    tokenized_text = tokenizer.tokenize(sentence)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    # Create a tensor of token indices\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "    # Load pre-trained model (weights)\n",
        "    model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "    model.eval()\n",
        "\n",
        "    misspelled_words = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Predict all tokens\n",
        "        outputs = model(tokens_tensor)\n",
        "        predictions = outputs[0]\n",
        "\n",
        "        # Iterate over each token in the input sentence\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            # Mask the token we are investigating\n",
        "            masked_index = i\n",
        "            tokenized_text_masked = tokenized_text.copy()\n",
        "            tokenized_text_masked[masked_index] = '[MASK]'\n",
        "            indexed_tokens_masked = tokenizer.convert_tokens_to_ids(tokenized_text_masked)\n",
        "            tokens_tensor_masked = torch.tensor([indexed_tokens_masked])\n",
        "\n",
        "            # Predict the masked token\n",
        "            outputs_masked = model(tokens_tensor_masked)\n",
        "            predictions_masked = outputs_masked[0]\n",
        "\n",
        "            # Get the predicted token\n",
        "            predicted_index = torch.argmax(predictions_masked[0, masked_index]).item()\n",
        "            predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
        "\n",
        "            # Compare the original token with the predicted token\n",
        "            if token != predicted_token:\n",
        "                misspelled_words.append((token, predicted_token))\n",
        "\n",
        "    return misspelled_words\n",
        "\n",
        "# Example usage\n",
        "sentence = \"Ths is a smple sentence with som misspelled wrds.\"\n",
        "u = 'a simple black spider is a fast face painting design that can make a big impavt on halloween'\n",
        "\n",
        "sentence = u\n",
        "\n",
        "misspelled_words = find_misspelled_words(sentence)\n",
        "print(\"Misspelled words:\", misspelled_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDP8x9WjUrsD",
        "outputId": "ee38151c-d543-4199-b51b-a28232b224de"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misspelled words: [('a', '\"'), ('simple', 'the'), ('black', 'the'), ('spider', '\"'), ('is', 'with'), ('fast', 'big'), ('face', 'black'), ('painting', '##less'), ('design', ','), ('can', 'will'), ('make', 'be'), ('big', '\"'), ('imp', 'big'), ('##av', 'can'), ('##t', '##o'), ('on', '.'), ('halloween', 'the')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## we want to feed it with one simple sentence"
      ],
      "metadata": {
        "id": "eeYJ8mnbjwst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sen = sent[0]\n",
        "s = []\n",
        "sentence = 'how ato you doing today'\n",
        "sentence = 'you are pretty beautipull .'\n",
        "\n",
        "u = sentence.split()\n",
        "for ind,i in enumerate(u):\n",
        "    l = ' '.join([u[c] if ind!=c else '[MASK]' for c in range(len(u))])\n",
        "    s.append(l)"
      ],
      "metadata": {
        "id": "xfLB_jbtgOX3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in s:\n",
        "    print(sentence)\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "    # print(inputs['input_ids'])\n",
        "    masked_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "    # print(masked_index)\n",
        "    # inputs['input_ids'][0][4] = 103\n",
        "    # Get predictions for the masked token\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs.to(device))\n",
        "    h = torch.softmax(outputs.logits[0], dim=1).max(1)[0]\n",
        "    print('Score for this sentence is: ',round(h[1:-1].mean().item(),4))\n",
        "    try:\n",
        "        masked_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "        predicted_token_ids = torch.topk(outputs.logits[0, masked_index], k=5).indices\n",
        "        predicted_tokens = [''.join(tok for tok in tokenizer.decode(token_id).split(' ')) for token_id in predicted_token_ids[0]]\n",
        "        print('Best Predicted Word: ',predicted_tokens)\n",
        "    except Exception as e:\n",
        "        print('oops!',e)\n",
        "    for i,j in zip(inputs['input_ids'][0].tolist(),h.tolist()):\n",
        "        print(f'{tokenizer.decode(i):<15} |  {i:<10} | {j:.4f} |')\n",
        "    print(50*'-')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCiYqKF0b1v8",
        "outputId": "c220d6cc-e757-4331-b72d-8b75074378c8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MASK] are pretty beautipull .\n",
            "Score for this sentence is:  0.7673\n",
            "Best Predicted Word:  ['they', 'you', 'we', 'these', 'both']\n",
            "[CLS]           |  101        | 0.0313 |\n",
            "[MASK]          |  103        | 0.6455 |\n",
            "are             |  2024       | 0.9835 |\n",
            "pretty          |  3492       | 0.6868 |\n",
            "beau            |  17935      | 0.9955 |\n",
            "##tip           |  25101      | 0.9031 |\n",
            "##ull           |  18083      | 0.1566 |\n",
            ".               |  1012       | 0.9999 |\n",
            "[SEP]           |  102        | 0.9347 |\n",
            "--------------------------------------------------\n",
            "you [MASK] pretty beautipull .\n",
            "Score for this sentence is:  0.6861\n",
            "Best Predicted Word:  ['are', 'look', 'were', 'looked', 'seem']\n",
            "[CLS]           |  101        | 0.0328 |\n",
            "you             |  2017       | 0.9725 |\n",
            "[MASK]          |  103        | 0.3575 |\n",
            "pretty          |  3492       | 0.8906 |\n",
            "beau            |  17935      | 0.9906 |\n",
            "##tip           |  25101      | 0.3926 |\n",
            "##ull           |  18083      | 0.1988 |\n",
            ".               |  1012       | 1.0000 |\n",
            "[SEP]           |  102        | 0.9869 |\n",
            "--------------------------------------------------\n",
            "you are [MASK] beautipull .\n",
            "Score for this sentence is:  0.721\n",
            "Best Predicted Word:  ['a', 'the', 'not', 'my', 'very']\n",
            "[CLS]           |  101        | 0.0335 |\n",
            "you             |  2017       | 0.9532 |\n",
            "are             |  2024       | 0.9988 |\n",
            "[MASK]          |  103        | 0.4853 |\n",
            "beau            |  17935      | 0.9986 |\n",
            "##tip           |  25101      | 0.5724 |\n",
            "##ull           |  18083      | 0.0388 |\n",
            ".               |  1012       | 1.0000 |\n",
            "[SEP]           |  102        | 0.9990 |\n",
            "--------------------------------------------------\n",
            "you are pretty [MASK] .\n",
            "Score for this sentence is:  0.7959\n",
            "Best Predicted Word:  ['good', 'smart', 'strong', 'beautiful', 'amazing']\n",
            "[CLS]           |  101        | 0.0303 |\n",
            "you             |  2017       | 0.9650 |\n",
            "are             |  2024       | 0.9830 |\n",
            "pretty          |  3492       | 0.9347 |\n",
            "[MASK]          |  103        | 0.0967 |\n",
            ".               |  1012       | 1.0000 |\n",
            "[SEP]           |  102        | 0.9969 |\n",
            "--------------------------------------------------\n",
            "you are pretty beautipull [MASK]\n",
            "Score for this sentence is:  0.7839\n",
            "Best Predicted Word:  ['.', ';', '!', '?', '##y']\n",
            "[CLS]           |  101        | 0.0332 |\n",
            "you             |  2017       | 1.0000 |\n",
            "are             |  2024       | 0.9999 |\n",
            "pretty          |  3492       | 0.9998 |\n",
            "beau            |  17935      | 0.9954 |\n",
            "##tip           |  25101      | 0.3499 |\n",
            "##ull           |  18083      | 0.2000 |\n",
            "[MASK]          |  103        | 0.9422 |\n",
            "[SEP]           |  102        | 0.9998 |\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## what if we mask token?"
      ],
      "metadata": {
        "id": "wvZmnB9sjsKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(sentence, return_tensors='pt')\n",
        "inputs['input_ids'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MGw86jJhY64",
        "outputId": "5100566a-cd85-49c5-b71c-aa0efac38bd3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 2129, 2012, 2080, 2017, 2725,  103,  102])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(inputs['input_ids'].shape[1]-2):\n",
        "    # print(i)\n",
        "    # print(sentence)\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "    # print(inputs['input_ids'][i])\n",
        "    inputs['input_ids'][0][i+1] = 103\n",
        "    # print(inputs['input_ids'][i])\n",
        "    # print(inputs['input_ids'])\n",
        "    masked_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "    # print(masked_index)\n",
        "    # inputs['input_ids'][0][4] = 103\n",
        "    # Get predictions for the masked token\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs.to(device))\n",
        "    h = torch.softmax(outputs.logits[0], dim=1).max(1)[0]\n",
        "    print(h[1:-1].mean())\n",
        "    try:\n",
        "        masked_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
        "        predicted_token_ids = torch.topk(outputs.logits[0, masked_index], k=5).indices\n",
        "        predicted_tokens = [''.join(tok for tok in tokenizer.decode(token_id).split(' ')) for token_id in predicted_token_ids[0]]\n",
        "        print(predicted_tokens)\n",
        "    except Exception as e:\n",
        "        print('oops!',e)\n",
        "    for i,j in zip(inputs['input_ids'][0].tolist(),h.tolist()):\n",
        "        print(tokenizer.decode(i),'|',i,'|',round(j,4),'|')\n",
        "    print(30*'-')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rckIjwbf6VR",
        "outputId": "37c62872-e4df-45ce-9c35-abbcde6b45d8"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8050, device='cuda:0')\n",
            "['what', \"'\", 'how', '\"', 'w']\n",
            "[CLS] | 101 | 0.0323 |\n",
            "[MASK] | 103 | 0.4621 |\n",
            "at | 2012 | 0.8865 |\n",
            "##o | 2080 | 0.5083 |\n",
            "you | 2017 | 0.9871 |\n",
            "doing | 2725 | 0.9998 |\n",
            "today | 2651 | 0.9862 |\n",
            "[SEP] | 102 | 0.9993 |\n",
            "------------------------------\n",
            "tensor(0.7969, device='cuda:0')\n",
            "['am', 'are', 'vo', 'much', '##mo']\n",
            "[CLS] | 101 | 0.0278 |\n",
            "how | 2129 | 0.9993 |\n",
            "[MASK] | 103 | 0.3276 |\n",
            "##o | 2080 | 0.4645 |\n",
            "you | 2017 | 0.9947 |\n",
            "doing | 2725 | 0.9956 |\n",
            "today | 2651 | 0.9999 |\n",
            "[SEP] | 102 | 0.9945 |\n",
            "------------------------------\n",
            "tensor(0.9764, device='cuda:0')\n",
            "['are', 'all', 'what', 'were', 'least']\n",
            "[CLS] | 101 | 0.0278 |\n",
            "how | 2129 | 0.9988 |\n",
            "at | 2012 | 0.95 |\n",
            "[MASK] | 103 | 0.9316 |\n",
            "you | 2017 | 0.9961 |\n",
            "doing | 2725 | 0.9945 |\n",
            "today | 2651 | 0.9871 |\n",
            "[SEP] | 102 | 0.9998 |\n",
            "------------------------------\n",
            "tensor(0.8000, device='cuda:0')\n",
            "['is', 'you', 'was', 'are', 'he']\n",
            "[CLS] | 101 | 0.032 |\n",
            "how | 2129 | 0.9967 |\n",
            "at | 2012 | 0.966 |\n",
            "##o | 2080 | 0.8893 |\n",
            "[MASK] | 103 | 0.4154 |\n",
            "doing | 2725 | 0.9828 |\n",
            "today | 2651 | 0.5498 |\n",
            "[SEP] | 102 | 0.9999 |\n",
            "------------------------------\n",
            "tensor(0.7046, device='cuda:0')\n",
            "['doing', 'feel', 'are', 'feeling', 'look']\n",
            "[CLS] | 101 | 0.0306 |\n",
            "how | 2129 | 1.0 |\n",
            "at | 2012 | 0.7392 |\n",
            "##o | 2080 | 0.4214 |\n",
            "you | 2017 | 0.9994 |\n",
            "[MASK] | 103 | 0.2163 |\n",
            "today | 2651 | 0.8515 |\n",
            "[SEP] | 102 | 0.9999 |\n",
            "------------------------------\n",
            "tensor(0.9852, device='cuda:0')\n",
            "['?', '.', '!', ';', '|']\n",
            "[CLS] | 101 | 0.0293 |\n",
            "how | 2129 | 1.0 |\n",
            "at | 2012 | 0.941 |\n",
            "##o | 2080 | 0.9887 |\n",
            "you | 2017 | 0.9954 |\n",
            "doing | 2725 | 0.9952 |\n",
            "[MASK] | 103 | 0.9911 |\n",
            "[SEP] | 102 | 0.9988 |\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}